{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook\n",
    "\n",
    "Figure out what POD (PUC Open Data) does.\n",
    "\n",
    "This has previously not worked, and has overlap with PLOOI,\n",
    "so I'm not quite sure about the status and future of this one\n",
    "(or whether it was always fine and just a bug of ours).\n",
    "\n",
    "Right now it's useful, to find "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pprint\n",
    "\n",
    "import requests\n",
    "\n",
    "import wetsuite.helpers.etree\n",
    "import wetsuite.helpers.localdata\n",
    "import wetsuite.helpers.koop_parse\n",
    "import wetsuite.helpers.format\n",
    "import wetsuite.helpers.date\n",
    "import wetsuite.helpers.notebook\n",
    "\n",
    "from wetsuite.datacollect.koop_repositories import PUCOpenData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for an SRU index summary, run:\n",
    "pprint.pprint( PUCOpenData().explain_parsed() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting slightly ahead of ourselves, documents we want to store go here:\n",
    "frbr_fetched  = wetsuite.helpers.localdata.LocalKV('frbr_fetched.db', key_type=str, value_type=bytes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cached, count_fetched, count_errors = 0,0,0\n",
    "\n",
    "def puc_callback(record):\n",
    "    global count_cached, count_fetched, count_errors\n",
    "    recordData     = record.find('recordData')        # the actual record \n",
    "    payload = recordData[0]\n",
    "    \n",
    "    # TODO: figure out data model, parse other parts - the below just throws disinct section's keys into the same dict. \n",
    "    # this is hoping for lack of collision, and bad practice in general, but good enough for debug\n",
    "    merged = {} \n",
    "    originalData = payload.find('originalData')\n",
    "    owmskern     = wetsuite.helpers.etree.kvelements_to_dict( originalData.find('meta/owmskern')   )\n",
    "    owmsmantel   = wetsuite.helpers.etree.kvelements_to_dict( originalData.find('meta/owmsmantel') ) \n",
    "    tpmeta       = wetsuite.helpers.etree.kvelements_to_dict( originalData.find('meta/tpmeta')     )\n",
    "    merged.update( owmskern )\n",
    "    merged.update( owmsmantel )\n",
    "    merged.update( tpmeta ) \n",
    "\n",
    "    docs_fetched = 0\n",
    "    # enrichedData will mention a list of (document type, document URL) \n",
    "    enriched = {}  # doctype -> url       assumption: at most one of each type\n",
    "    for ediu in payload.find('enrichedData').findall('itemUrl'):\n",
    "        enriched[ ediu.get('manifestation') ] = ediu.text.strip()   \n",
    "    merged.update( enriched )   # should arguably be more structured\n",
    "\n",
    "    # given a list of types like  html, metadata, odt, pdf,  choose just preferred forms to avoid duplication\n",
    "    for chosen_type in wetsuite.helpers.koop_parse.prefer_types( enriched.keys() ):\n",
    "        itemurl = enriched[chosen_type]\n",
    "        docs_fetched += 1\n",
    "        try:\n",
    "            _, came_from_cache = wetsuite.helpers.localdata.cached_fetch( frbr_fetched, itemurl )\n",
    "            if came_from_cache:\n",
    "                #print('CACHED', itemurl)\n",
    "                count_cached += 1\n",
    "            else:\n",
    "                #print('FETCHED', itemurl)\n",
    "                count_fetched += 1\n",
    "        except requests.exceptions.ReadTimeout:\n",
    "                print('TIMEOUT', itemurl)\n",
    "                count_errors += 1\n",
    "        except ValueError as ve:\n",
    "                print('error %s'%ve, itemurl)\n",
    "                count_errors += 1\n",
    "\n",
    "    if docs_fetched == 0:\n",
    "        print(\"Didn't select any documents from\")\n",
    "        payload = wetsuite.helpers.etree.indent(payload)\n",
    "        print( wetsuite.helpers.etree.tostring( payload, encoding='unicode' ) )\n",
    "        #pprint.pprint( merged )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sru_puc = PUCOpenData()\n",
    "\n",
    "def search_retrieve_progressbar(query, callback):\n",
    "    global count_cached, count_fetched, count_errors \n",
    "    count_cached, count_fetched, count_errors = 0,0,0\n",
    "    sru_puc.search_retrieve(query) # only really for the amount\n",
    "    numrec = sru_puc.num_records()\n",
    "    print( \"%d items for %r\"%(numrec, query) )\n",
    "    pb = wetsuite.helpers.notebook.progress_bar( numrec, description=query )\n",
    "    def cbwrap(record):\n",
    "        pb.value += 1\n",
    "        pb.description = '%d fetched, %d cached'%( count_fetched, count_cached )\n",
    "        callback(record)\n",
    "    sru_puc.search_retrieve_many( query, up_to=50000, at_a_time=1000, callback=cbwrap, wait_between_sec=0.01) \n",
    "\n",
    "\n",
    "for frd, tod in reversed( wetsuite.helpers.date.date_ranges('2021-01-01', datetime.datetime.now(), 5, '%Y-%m-%d') ): \n",
    "    search_retrieve_progressbar('dt.modified >= %s and dt.modified <= %s'%(frd,tod), callback=puc_callback)    \n",
    "\n",
    "\n",
    "#search_retrieve_progressbar('dt.modified >= 2024-01-01', callback=puc_callback)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in ['dt.modified >= 2024-01-01']:\n",
    "    sru_puc.search_retrieve(query)\n",
    "    print(\"%d results for %r\"%(sru_puc.num_records(), query))\n",
    "\n",
    "    sru_puc.search_retrieve_many( query, up_to=50000, callback=puc_callback, wait_between_sec=0.01) \n",
    "\n",
    "#sru_puc.search_retrieve_many('dt.modified>=2022-01-01 and dt.modified<=2022-12-31', up_to=50000, callback=puc_callback)\n",
    "#sru_puc.search_retrieve_many('dcterms.modified>=2021-01-01 and dcterms.modified<=2021-12-31', up_to=50000, callback=puc_callback) \n",
    "#sru_puc.search_retrieve_many('dcterms.modified>=2020-01-01 and dcterms.modified<=2020-12-31', up_to=50000, callback=puc_callback) \n",
    "#sru_puc.search_retrieve_many('dcterms.modified>=2019-01-01 and dcterms.modified<=2019-12-31', up_to=50000, callback=puc_callback) \n",
    "#sru_puc.search_retrieve_many('dcterms.modified>=2018-01-01 and dcterms.modified<=2018-12-31', up_to=50000, callback=puc_callback) \n",
    "#sru_puc.search_retrieve_many('dcterms.modified>=2017-01-01 and dcterms.modified<=2017-12-31', up_to=50000, callback=puc_callback) \n",
    "#sru_puc.search_retrieve_many('dcterms.modified>=2016-01-01 and dcterms.modified<=2016-12-31', up_to=50000, callback=puc_callback) \n",
    "#sru_puc.search_retrieve_many('dcterms.modified>=2015-01-01 and dcterms.modified<=2015-12-31', up_to=50000, callback=puc_callback) \n",
    "\n",
    "#sru_puc.search_retrieve_many('dcterms.identifier==BWBR0004825', callback=puc_callback) # Reglement verkeersregels en verkeerstekens, to see how images work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
